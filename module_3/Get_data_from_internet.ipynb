{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('main_task.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.tripadvisor.com//Restaurant_Review-g187849-d7734583-Reviews-Gioby_Pizzeria-Milan_Lombardy.html'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make function to obtain the link (return string)\n",
    "def get_url(df, idx):\n",
    "    \"\"\" Returns full link \n",
    "        df - dataframe\n",
    "        isx - index of row to extract the link\"\"\"\n",
    "    \n",
    "    return 'https://www.tripadvisor.com/' + df['URL_TA'][idx]\n",
    "\n",
    "link = get_url(df, 320)\n",
    "link"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "python modules need to be installed by pip or conda  \n",
    "\n",
    "- conda install requests  \n",
    "- conda install beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time        # measure finish and start  execution time\n",
    "import requests    # get link\n",
    "import bs4         # access HTML code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_evaluation(df):\n",
    "    \"\"\" Get dataframe and obtain new features based on the evaluation \"\"\"\n",
    "    \n",
    "    # Make new column with URL\n",
    "    df['URL'] = df[\"URL_TA\"].apply(lambda x: 'https://www.tripadvisor.com/' + x)\n",
    "    \n",
    "    # Create new columns\n",
    "    df['nr_reviews'] = 0\n",
    "    df['excellent'] = 0\n",
    "    df['v_good'] = 0\n",
    "    df['average'] = 0\n",
    "    df['poor'] = 0\n",
    "    df['terrible'] = 0\n",
    "    \n",
    "    #listik = []\n",
    "    \n",
    "    for item in df.index:\n",
    "\n",
    "        # get the link and access the html page\n",
    "        res = requests.get(df[\"URL\"][item])\n",
    "        test_read = bs4.BeautifulSoup(res.text, 'html.parser')\n",
    "        \n",
    "        \n",
    "        # get info from the internet\n",
    "        review = test_read.select('#REVIEWS > div.prw_rup.prw_common_location_content_header_resp > div > div.title_text')\n",
    "        excellent = test_read.select('#taplc_detail_filters_rr_resp_0 > div > div.noncollapsible > div.prw_rup.prw_filters_detail_checkbox > div > div.content > div > div:nth-child(1) > span.row_num')\n",
    "        vg = test_read.select('#taplc_detail_filters_rr_resp_0 > div > div.noncollapsible > div.prw_rup.prw_filters_detail_checkbox > div > div.content > div > div:nth-child(2) > span.row_num')\n",
    "        av = test_read.select('#taplc_detail_filters_rr_resp_0 > div > div.noncollapsible > div.prw_rup.prw_filters_detail_checkbox > div > div.content > div > div:nth-child(3) > span.row_num')\n",
    "        poor = test_read.select('#taplc_detail_filters_rr_resp_0 > div > div.noncollapsible > div.prw_rup.prw_filters_detail_checkbox > div > div.content > div > div:nth-child(4) > span.row_num')\n",
    "        ter = test_read.select('#taplc_detail_filters_rr_resp_0 > div > div.noncollapsible > div.prw_rup.prw_filters_detail_checkbox > div > div.content > div > div:nth-child(5) > span.row_num')\n",
    "        \n",
    "        # in case of bad link or incorrect paper or 0 reviews\n",
    "        if review == [] or review[0].getText() == 'Reviews  (0)' or review[0].getText() == 'Be the first to write a review ':\n",
    "            # Set value for each row\n",
    "            df.at[item,'nr_reviews'] = 0\n",
    "            df.at[item, 'excellent'] = 0\n",
    "            df.at[item, 'v_good'] = 0\n",
    "            df.at[item, 'average'] = 0\n",
    "            df.at[item, 'poor'] = 0\n",
    "            df.at[item, 'terrible'] = 0\n",
    "        \n",
    "        # in case of a good link\n",
    "        else:\n",
    "            # Set value for each row\n",
    "            df.at[item,'nr_reviews'] = int(review[0].getText().replace('Reviews ', '').replace(' (', '').replace(')', '').replace(',',''))\n",
    "            df.at[item, 'excellent'] = int(excellent[0].getText().replace(',',''))\n",
    "            df.at[item, 'v_good'] = int(vg[0].getText().replace(',',''))\n",
    "            df.at[item, 'average'] = int(av[0].getText().replace(',',''))\n",
    "            df.at[item, 'poor'] = int(poor[0].getText().replace(',',''))\n",
    "            df.at[item, 'terrible'] = int(ter[0].getText().replace(',',''))\n",
    "            \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time to execute the code is 145.71943497657776 seconds\n"
     ]
    }
   ],
   "source": [
    "# MAke a new df for test\n",
    "new_df = df[0:10].copy()\n",
    "\n",
    "start = time.time()\n",
    "a = get_evaluation(new_df)\n",
    "finish = time.time()\n",
    "\n",
    "print(f'Total time to execute the code is {finish - start} seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of processors:  4\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing as mp\n",
    "from multiprocessing import  Pool\n",
    "\n",
    "print(\"Number of processors: \", mp.cpu_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parrallel computing with pandas. Split dataset into core count\n",
    "# Simultaniously takse data from the internet\n",
    "# joins back the dataset\n",
    "def parallelize_dataframe(df, func, n_cores=20):\n",
    "    df_split = np.array_split(df, n_cores)\n",
    "    pool = Pool(n_cores)\n",
    "    df = pd.concat(pool.map(func, df_split))\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAke a new df for test\n",
    "new_df = df[0:10].copy()\n",
    "\n",
    "start = time.time()\n",
    "train = parallelize_dataframe(new_df, get_evaluation)\n",
    "finish = time.time()\n",
    "\n",
    "print(f'Total time to execute the code is {finish - start} seconds')\n",
    "train"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
